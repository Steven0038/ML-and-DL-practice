{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KYaoTUrNDGk",
        "colab_type": "code",
        "outputId": "defc1752-4532-4e9c-e3ce-da79dd07c383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw5nhJlH3Vjf",
        "colab_type": "code",
        "outputId": "5a43a3e1-6e61-42c0-b8e8-af370c5ba010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSku6gwq2mHP",
        "colab_type": "code",
        "outputId": "2f7ee29a-a98d-4188-8d33-147427b13970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import sys\n",
        "FOLDER_PATH = '/content/drive/My Drive/DL/keras-yolo3-blood-cell'\n",
        "sys.path.append(FOLDER_PATH)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyAHLQiJ2mHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''loads the classes'''\n",
        "def get_classes(classes_path):\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "'''loads the anchors from a file'''\n",
        "def get_anchors(anchors_path):\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzsB6f8m2mHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(input_shape, anchors, num_classes, load_pretrained=False, freeze_body=2, weights_path=''):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print(f'Create YOLOv3 model with {num_anchors} anchors and {num_classes} classes.')\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3aVW9eG2mHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''data generator for fit_generator'''\n",
        "def data_generator(folder_path, annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(folder_path, annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(folder_path, annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(folder_path, annotation_lines, batch_size, input_shape, anchors, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIlKwFkK2mHb",
        "colab_type": "code",
        "outputId": "479060d0-38f1-40df-8698-6d59fd2a4263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "annotation_path = os.path.join(FOLDER_PATH, 'dataset/train_txt/anno.txt')\n",
        "classes_path = os.path.join(FOLDER_PATH, 'model_data/bccd_classes.txt')\n",
        "anchors_path = os.path.join(FOLDER_PATH, 'model_data/yolo_anchors.txt')\n",
        "class_names = get_classes(classes_path)\n",
        "num_classes = len(class_names)\n",
        "anchors = get_anchors(anchors_path)\n",
        "\n",
        "input_shape = (416,416) # multiple of 32, hw\n",
        "\n",
        "model = create_model(input_shape, anchors, num_classes, load_pretrained=False, freeze_body=2) # make sure you know what you freeze\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "checkpoint = ModelCheckpoint('drive/My Drive/ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "val_split = 0.1\n",
        "with open(annotation_path) as f:\n",
        "    lines = f.readlines()\n",
        "np.random.seed(5566)\n",
        "np.random.shuffle(lines)\n",
        "np.random.seed(None)\n",
        "num_val = int(len(lines)*val_split)\n",
        "num_train = len(lines) - num_val\n",
        "\n",
        "# Train with frozen layers first, to get a stable loss.\n",
        "# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "if True:\n",
        "    model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "        # use custom yolo_loss Lambda layer.\n",
        "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "    batch_size = 4\n",
        "    print(f'Train on {num_train} samples, val on {num_val} samples, with batch size {batch_size}.')\n",
        "    model.fit_generator(data_generator_wrapper(FOLDER_PATH, lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(FOLDER_PATH, lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=50,\n",
        "            initial_epoch=0,\n",
        "            callbacks=[checkpoint])\n",
        "#     model.save_weights('trained_weights_stage_1.h5')\n",
        "\n",
        "# Unfreeze and continue training, to fine-tune.\n",
        "# Train longer if the result is not good.\n",
        "if True:\n",
        "    for i in range(len(model.layers)):\n",
        "        model.layers[i].trainable = True\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "    print('Unfreeze all of the layers.')\n",
        "\n",
        "    batch_size = 4 # note that more GPU memory is required after unfreezing the body\n",
        "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "    model.fit_generator(data_generator_wrapper(FOLDER_PATH, lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "        steps_per_epoch=max(1, num_train//batch_size),\n",
        "        validation_data=data_generator_wrapper(FOLDER_PATH, lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "        validation_steps=max(1, num_val//batch_size),\n",
        "        epochs=100,\n",
        "        initial_epoch=50,\n",
        "        callbacks=[checkpoint, reduce_lr, early_stopping])\n",
        "#     model.save_weights('trained_weights_final.h5')\n",
        "\n",
        "# Further training if needed."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Create YOLOv3 model with 9 anchors and 3 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3170: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 328 samples, val on 36 samples, with batch size 4.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/50\n",
            "45/82 [===============>..............] - ETA: 1:52 - loss: 1498.7124"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:718: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "82/82 [==============================] - 372s 5s/step - loss: 933.4259 - val_loss: 678.4594\n",
            "Epoch 2/50\n",
            "82/82 [==============================] - 31s 379ms/step - loss: 185.9964 - val_loss: 219.4645\n",
            "Epoch 3/50\n",
            "82/82 [==============================] - 33s 397ms/step - loss: 157.0218 - val_loss: 190.6543\n",
            "Epoch 4/50\n",
            "82/82 [==============================] - 29s 359ms/step - loss: 143.2828 - val_loss: 134.7038\n",
            "Epoch 5/50\n",
            "82/82 [==============================] - 33s 397ms/step - loss: 135.1558 - val_loss: 166.3753\n",
            "Epoch 6/50\n",
            "82/82 [==============================] - 33s 401ms/step - loss: 132.8342 - val_loss: 108.4821\n",
            "Epoch 7/50\n",
            "82/82 [==============================] - 33s 404ms/step - loss: 136.8762 - val_loss: 249.8204\n",
            "Epoch 8/50\n",
            "82/82 [==============================] - 33s 401ms/step - loss: 133.5272 - val_loss: 115.9633\n",
            "Epoch 9/50\n",
            "82/82 [==============================] - 33s 403ms/step - loss: 130.7564 - val_loss: 156.9724\n",
            "Epoch 10/50\n",
            "82/82 [==============================] - 33s 404ms/step - loss: 130.9162 - val_loss: 133.9780\n",
            "Epoch 11/50\n",
            "82/82 [==============================] - 33s 405ms/step - loss: 127.1129 - val_loss: 127.5761\n",
            "Epoch 12/50\n",
            "82/82 [==============================] - 33s 406ms/step - loss: 123.0988 - val_loss: 128.2591\n",
            "Epoch 13/50\n",
            "82/82 [==============================] - 33s 404ms/step - loss: 123.2764 - val_loss: 129.1577\n",
            "Epoch 14/50\n",
            "82/82 [==============================] - 33s 407ms/step - loss: 116.1138 - val_loss: 137.4907\n",
            "Epoch 15/50\n",
            "82/82 [==============================] - 33s 405ms/step - loss: 113.0648 - val_loss: 167.9126\n",
            "Epoch 16/50\n",
            "82/82 [==============================] - 33s 405ms/step - loss: 112.4013 - val_loss: 118.7323\n",
            "Epoch 17/50\n",
            "82/82 [==============================] - 33s 407ms/step - loss: 100.9063 - val_loss: 108.8915\n",
            "Epoch 18/50\n",
            "82/82 [==============================] - 33s 405ms/step - loss: 100.4733 - val_loss: 91.2433\n",
            "Epoch 19/50\n",
            "82/82 [==============================] - 34s 409ms/step - loss: 95.3531 - val_loss: 147.4135\n",
            "Epoch 20/50\n",
            "82/82 [==============================] - 33s 403ms/step - loss: 95.8083 - val_loss: 142.2224\n",
            "Epoch 21/50\n",
            "82/82 [==============================] - 33s 405ms/step - loss: 91.1720 - val_loss: 105.6025\n",
            "Epoch 22/50\n",
            "82/82 [==============================] - 33s 404ms/step - loss: 92.1356 - val_loss: 121.3812\n",
            "Epoch 23/50\n",
            "82/82 [==============================] - 33s 403ms/step - loss: 89.0618 - val_loss: 92.6864\n",
            "Epoch 24/50\n",
            "82/82 [==============================] - 33s 405ms/step - loss: 85.6019 - val_loss: 65.1686\n",
            "Epoch 25/50\n",
            "82/82 [==============================] - 34s 410ms/step - loss: 84.5756 - val_loss: 82.1991\n",
            "Epoch 26/50\n",
            "82/82 [==============================] - 33s 407ms/step - loss: 83.2636 - val_loss: 82.9808\n",
            "Epoch 27/50\n",
            "82/82 [==============================] - 33s 406ms/step - loss: 86.6017 - val_loss: 112.0479\n",
            "Epoch 28/50\n",
            "82/82 [==============================] - 33s 404ms/step - loss: 83.4840 - val_loss: 92.5011\n",
            "Epoch 29/50\n",
            "82/82 [==============================] - 34s 410ms/step - loss: 81.4525 - val_loss: 124.5351\n",
            "Epoch 30/50\n",
            "82/82 [==============================] - 34s 409ms/step - loss: 81.7053 - val_loss: 123.0732\n",
            "Epoch 31/50\n",
            "82/82 [==============================] - 34s 409ms/step - loss: 85.5061 - val_loss: 88.0984\n",
            "Epoch 32/50\n",
            "82/82 [==============================] - 33s 405ms/step - loss: 83.0939 - val_loss: 114.1008\n",
            "Epoch 33/50\n",
            "82/82 [==============================] - 33s 403ms/step - loss: 80.2987 - val_loss: 115.0987\n",
            "Epoch 34/50\n",
            "82/82 [==============================] - 33s 408ms/step - loss: 77.7539 - val_loss: 70.9291\n",
            "Epoch 35/50\n",
            "82/82 [==============================] - 34s 411ms/step - loss: 79.0600 - val_loss: 110.2394\n",
            "Epoch 36/50\n",
            "82/82 [==============================] - 33s 408ms/step - loss: 78.8890 - val_loss: 111.9974\n",
            "Epoch 37/50\n",
            "82/82 [==============================] - 33s 407ms/step - loss: 79.5361 - val_loss: 88.1825\n",
            "Epoch 38/50\n",
            "82/82 [==============================] - 34s 414ms/step - loss: 75.2937 - val_loss: 79.4689\n",
            "Epoch 39/50\n",
            "82/82 [==============================] - 33s 408ms/step - loss: 74.3798 - val_loss: 82.1862\n",
            "Epoch 40/50\n",
            "82/82 [==============================] - 33s 399ms/step - loss: 75.5933 - val_loss: 92.1516\n",
            "Epoch 41/50\n",
            "82/82 [==============================] - 34s 412ms/step - loss: 73.0452 - val_loss: 87.8780\n",
            "Epoch 42/50\n",
            "82/82 [==============================] - 34s 414ms/step - loss: 74.0708 - val_loss: 91.3319\n",
            "Epoch 43/50\n",
            "82/82 [==============================] - 34s 415ms/step - loss: 74.7570 - val_loss: 129.7633\n",
            "Epoch 44/50\n",
            "82/82 [==============================] - 33s 406ms/step - loss: 74.2107 - val_loss: 76.0448\n",
            "Epoch 45/50\n",
            "82/82 [==============================] - 34s 412ms/step - loss: 73.2212 - val_loss: 101.2908\n",
            "Epoch 46/50\n",
            "82/82 [==============================] - 34s 414ms/step - loss: 73.2595 - val_loss: 79.4335\n",
            "Epoch 47/50\n",
            "82/82 [==============================] - 33s 402ms/step - loss: 73.4060 - val_loss: 76.6641\n",
            "Epoch 48/50\n",
            "82/82 [==============================] - 33s 402ms/step - loss: 72.2242 - val_loss: 83.0540\n",
            "Epoch 49/50\n",
            "82/82 [==============================] - 33s 398ms/step - loss: 73.2704 - val_loss: 79.9034\n",
            "Epoch 50/50\n",
            "82/82 [==============================] - 33s 402ms/step - loss: 71.2180 - val_loss: 86.9297\n",
            "Unfreeze all of the layers.\n",
            "Train on 328 samples, val on 36 samples, with batch size 4.\n",
            "Epoch 51/100\n",
            "82/82 [==============================] - 43s 526ms/step - loss: 68.8962 - val_loss: 62.5361\n",
            "Epoch 52/100\n",
            "82/82 [==============================] - 30s 370ms/step - loss: 66.5937 - val_loss: 69.6477\n",
            "Epoch 53/100\n",
            "82/82 [==============================] - 33s 397ms/step - loss: 65.8774 - val_loss: 60.4121\n",
            "Epoch 54/100\n",
            "82/82 [==============================] - 32s 395ms/step - loss: 65.4934 - val_loss: 79.2544\n",
            "Epoch 55/100\n",
            "82/82 [==============================] - 32s 394ms/step - loss: 65.9897 - val_loss: 67.0499\n",
            "Epoch 56/100\n",
            "82/82 [==============================] - 32s 390ms/step - loss: 65.9278 - val_loss: 105.8143\n",
            "\n",
            "Epoch 00056: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 57/100\n",
            "82/82 [==============================] - 30s 363ms/step - loss: 65.6983 - val_loss: 60.1637\n",
            "Epoch 58/100\n",
            "82/82 [==============================] - 32s 394ms/step - loss: 64.6990 - val_loss: 65.2546\n",
            "Epoch 59/100\n",
            "82/82 [==============================] - 32s 396ms/step - loss: 63.8413 - val_loss: 60.2073\n",
            "Epoch 60/100\n",
            "82/82 [==============================] - 32s 387ms/step - loss: 63.3254 - val_loss: 54.4797\n",
            "Epoch 61/100\n",
            "82/82 [==============================] - 32s 392ms/step - loss: 63.8637 - val_loss: 61.7697\n",
            "Epoch 62/100\n",
            "82/82 [==============================] - 32s 389ms/step - loss: 63.5742 - val_loss: 52.8309\n",
            "Epoch 63/100\n",
            "82/82 [==============================] - 31s 383ms/step - loss: 63.9334 - val_loss: 83.1565\n",
            "Epoch 64/100\n",
            "82/82 [==============================] - 32s 385ms/step - loss: 63.6059 - val_loss: 62.4931\n",
            "Epoch 65/100\n",
            "82/82 [==============================] - 32s 392ms/step - loss: 63.2132 - val_loss: 80.8180\n",
            "\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 66/100\n",
            "82/82 [==============================] - 32s 390ms/step - loss: 63.3077 - val_loss: 86.5742\n",
            "Epoch 67/100\n",
            "82/82 [==============================] - 32s 391ms/step - loss: 62.6807 - val_loss: 63.7724\n",
            "Epoch 68/100\n",
            "82/82 [==============================] - 32s 391ms/step - loss: 63.6430 - val_loss: 60.4869\n",
            "\n",
            "Epoch 00068: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 69/100\n",
            "82/82 [==============================] - 32s 386ms/step - loss: 63.0010 - val_loss: 68.8800\n",
            "Epoch 70/100\n",
            "82/82 [==============================] - 32s 389ms/step - loss: 62.7217 - val_loss: 61.7718\n",
            "Epoch 71/100\n",
            "82/82 [==============================] - 32s 390ms/step - loss: 62.9195 - val_loss: 86.9564\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 72/100\n",
            "82/82 [==============================] - 32s 385ms/step - loss: 63.2730 - val_loss: 59.0666\n",
            "Epoch 00072: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Ju4Zah2mHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}